## KERAS-DCGANImplementation of http://arxiv.org/abs/1511.06434 with the (awesome) [keras](https://github.com/fchollet/keras) library, for generating artificial images with deep learning.This trains two adversarial deep learning models on real images, in order to produce artificial images that look real.The generator model tries to produce images that look real and get a high score from the discriminator.The discriminator model tries to tell apart between real images and artificial images from the generator.---This assumes theano ordering.You can still use this with tensorflow, by setting "image_dim_ordering": "th" in ~/.keras/keras.json (although this will be slower).---## Usage**Training:** `python dcgan.py --mode train --batch_size <batch_size>`ex`python dcgan.py --mode train --path ~/images --batch_size 128`**Image generation:**`python dcgan.py --mode generate --batch_size <batch_size>``python dcgan.py --mode generate --batch_size <batch_size> --nice` : top 5% images according to discriminatorpython dcgan.py --mode generate --batch_size 128---## Result**generated images :**![generated_image.png](./assets/generated_image.png)![nice_generated_image.png](./assets/nice_generated_image.png)**train process :**![training_process.gif](./assets/training_process.gif)---## 事前知識※DIC受講生の場合、Keras入門を参照### keras`keras document`https://keras.io/ja/## import`Dence`https://keras.io/ja/layers/core/通常の全結合ニューラルネットワークレイヤー```pymodel = Sequential()model.add(Dense(32, input_shape=(784,)))````Reshape`https://keras.io/ja/layers/core/>あるshapeに出力を変形する．```py# as first layer in a Sequential modelmodel = Sequential()model.add(Reshape((3, 4), input_shape=(12,)))# now: model.output_shape == (None, 3, 4)# note: `None` is the batch dimension# as intermediate layer in a Sequential modelmodel.add(Reshape((6, 2)))# now: model.output_shape == (None, 6, 2)# also supports shape inference using `-1` as dimensionmodel.add(Reshape((-1, 2, 2)))# now: model.output_shape == (Non````Activation````引数activation： 使用する活性化関数名 (activationsを参照)， もしくは，TheanoかTensorFlowオペレーション．````Flatten`https://keras.io/ja/layers/core/#flatten```keras.layers.core.Flatten()入力を平滑化する．バッチサイズに影響されない．``````pymodel = Sequential()model.add(Conv2D(64, (3, 3), input_shape=(3, 32, 32)))# now: model.output_shape == (None, 64, 32, 32)model.add(Flatten())# now: model.output_shape == (None, 65536)````BatchNormalization`[from: Batch normalization layer (Ioffe and Szegedy, 2014)](https://arxiv.org/abs/1502.03167)各バッチ毎に前の層の出力（このレイヤーへの入力）を正規化します． つまり，平均を0，標準偏差値を1に近づける変換を適用します．https://keras.io/ja/layers/normalization/`UpSampling2D`https://keras.io/ja/layers/convolutional/#upsampling2d```データの行と列をそれぞれsize[0]及びsize[1]回繰り返します．```![](https://zo7.github.io/img/2016-09-25-generating-faces/deconv.png)>https://zo7.github.io/blog/2016/09/25/generating-faces.html`Conv2D`https://keras.io/ja/layers/convolutional/#conv2d```2次元入力をフィルターする畳み込み層．use_biasをTrueにすると，バイアスベクトルが出力に加えられます．activationがNoneでない場合，指定した活性化関数が出力に適用されます．このレイヤーをモデルの第1層に使うときはキーワード引数input_shape （整数のタプル，サンプル軸を含まない）を指定してください． 例えば，data_format="channels_last"のとき，128x128 RGB画像ではinput_shape=(128, 128, 3)となります．````MaxPooling2D`空間データのマックスプーリング演算．https://keras.io/ja/layers/pooling/#maxpooling2d`SGD` https://keras.io/ja/optimizers/#sgd```モーメンタム，学習率減衰，Nesterov momentumをサポートした確率的勾配降下法．```## generator_model![](https://elix-tech.github.io/images/2017/gan/dcgan_generator.png)[Radford et al. (2015)](https://arxiv.org/abs/1511.06434)より引用## 畳み込みアニメーション`from`https://github.com/vdumoulin/conv_arithmetic#convolution-animations<table style="width:100%">  <tr>    <td><img src="gif/no_padding_no_strides.gif"></td>    <td><img src="gif/arbitrary_padding_no_strides.gif"></td>    <td><img src="gif/same_padding_no_strides.gif"></td>    <td><img src="gif/full_padding_no_strides.gif"></td>  </tr>  <tr>    <td>No padding, no strides</td>    <td>Arbitrary padding, no strides</td>    <td>Half padding, no strides</td>    <td>Full padding, no strides</td>  </tr>  <tr>    <td><img src="gif/no_padding_no_strides_transposed.gif"></td>    <td><img src="gif/arbitrary_padding_no_strides_transposed.gif"></td>    <td><img src="gif/same_padding_no_strides_transposed.gif"></td>    <td><img src="gif/full_padding_no_strides_transposed.gif"></td>  </tr>  <tr>    <td>No padding, no strides, transposed</td>    <td>Arbitrary padding, no strides, transposed</td>    <td>Half padding, no strides, transposed</td>    <td>Full padding, no strides, transposed</td>  </tr>  <tr>    <td><img src="gif/no_padding_strides.gif"></td>    <td><img src="gif/padding_strides.gif"></td>    <td><img src="gif/padding_strides_odd.gif"></td>    <td></td>  </tr>  <tr>    <td>No padding, strides</td>    <td>Padding, strides</td>    <td>Padding, strides (odd)</td>    <td></td>  </tr>  <tr>    <td><img src="gif/no_padding_strides_transposed.gif"></td>    <td><img src="gif/padding_strides_transposed.gif"></td>    <td><img src="gif/padding_strides_odd_transposed.gif"></td>    <td></td>  </tr>  <tr>    <td>No padding, strides, transposed</td>    <td>Padding, strides, transposed</td>    <td>Padding, strides, transposed (odd)</td>    <td></td>  </tr>  <tr>    <td><img src="gif/dilation.gif"></td>    <td></td>    <td></td>    <td></td>  </tr>  <tr>    <td>No padding, no stride, dilation</td>    <td></td>    <td></td>    <td></td>  </tr></table>